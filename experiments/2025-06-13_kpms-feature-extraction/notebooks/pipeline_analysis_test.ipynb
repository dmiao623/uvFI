{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759f2c7-814a-4a89-9e20-0fbc6f1fdac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "analysis_lib = \"/projects/kumar-lab/miaod/projects/uvFI/pipelines/feature-extraction/src\"\n",
    "sys.path.append(analysis_lib)\n",
    "\n",
    "import features, preprocess, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbb8fe-80e4-4d80-8648-219dc0705c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "expr_dir = Path(\"/projects/kumar-lab/miaod/projects/uvFI/experiments/2025-06-13_kpms-feature-extraction/\")\n",
    "outputs_dir = expr_dir / \"outputs\"\n",
    "\n",
    "project_dir = expr_dir / \"data\"\n",
    "model_name = \"2025-06-13_kpms-inference_data\"\n",
    "pose_dir = expr_dir / \"data/2025-06-13_kpms-inference_data/poses_csv\"\n",
    "\n",
    "utils.set_project_info(str(project_dir), model_name, str(pose_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb25b9-59f7-4d4e-a719-fab36f52e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.create_groups_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe33e7-32ea-4e3f-a996-853763f77228",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.combine_inference_results(r\"^out_\\d+\\.h5$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b528527e-ad82-4e4c-886a-eb8b07d28416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keypoint_moseq as kpms\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm \n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "\n",
    "from config import FIGURE_DIR\n",
    "from utils import _read_project_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261c4c4-3ef4-45e2-8070-504845ae76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_t = Dict[str, Dict[str, np.ndarray]]\n",
    "moseq_df_t = pd.DataFrame\n",
    "stats_df_t = pd.DataFrame\n",
    "analyses_t = Dict[str, Union[results_t, moseq_df_t, stats_df_t]]\n",
    "\n",
    "def load_analyses(\n",
    "    min_frequency: float=0.005, \n",
    "    fps: int=30\n",
    ") -> Tuple[results_t, moseq_df_t, stats_df_t]:\n",
    "    project_dir, model_name = _read_project_info(\"project_dir\", \"model_name\")\n",
    "    results = kpms.load_results(project_dir, model_name)\n",
    "\n",
    "    moseq_df = kpms.compute_moseq_df(project_dir, model_name, smooth_heading=True)\n",
    "    stats_df = kpms.compute_stats_df(project_dir, model_name, moseq_df,\n",
    "                                     min_frequency=min_frequency, groupby=[\"name\"], fps=fps)\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"moseq_df\": moseq_df,\n",
    "        \"stats_df\": stats_df,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49894e5c-316f-4fe1-ab6f-b03daeb60968",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = load_analyses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f47e4-9381-4d8e-a13e-a70405f79b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syllable_lempel_ziv(analyses: analyses_t):\n",
    "    def lempel_ziv(seq: Sequence) -> int:\n",
    "        n, i, phrases = len(seq), 0, 0\n",
    "        dictionary = set()\n",
    "        while i < n:\n",
    "            k = 1\n",
    "            while i + k <= n and tuple(seq[i:i+k]) in dictionary:\n",
    "                k += 1\n",
    "            dictionary.add(tuple(seq[i:i+k]))\n",
    "            phrases += 1\n",
    "            i += k\n",
    "        return phrases\n",
    "\n",
    "    def normalized_lempel_ziv(seq: Sequence) -> float:\n",
    "        n = len(seq)\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        sigma = len(set(seq))\n",
    "        if sigma <= 1 or n <= 1:\n",
    "            return 0.0\n",
    "        lz = lempel_ziv(seq)\n",
    "        norm = lz * math.log(sigma) / (n * math.log(n))\n",
    "        return norm\n",
    "\n",
    "    results = analyses[\"results\"]\n",
    "    ret = [\n",
    "        normalized_lempel_ziv(info[\"syllable\"])\n",
    "        for name, info in tqdm(results.items(), desc=\"computing get_syllable_lempel_ziv\")\n",
    "    ]\n",
    "    return {\"syllable_lempel_ziv\": ret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71af4aa-c05a-483c-9f15-dac89f77a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_lz_output = get_syllable_lempel_ziv(analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b3fe0-a3ae-41e6-b52f-ea8c71d97ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_embedding_statistics(analyses: analyses_t):\n",
    "    results = analyses[\"results\"]\n",
    "\n",
    "    stats = []\n",
    "    for name, info in tqdm(results.items(), desc=\"computing get_latent_embedding_statistics\"):\n",
    "        latent_embeddings = info[\"latent_state\"]\n",
    "\n",
    "        means   = latent_embeddings.mean(axis=0)\n",
    "        medians = np.median(latent_embeddings, axis=0)\n",
    "        stds    = latent_embeddings.std(axis=0, ddof=0)\n",
    "        \n",
    "        features = np.concatenate((means, medians, stds))\n",
    "        stats.append(features)\n",
    "    \n",
    "    trans = list(map(list, zip(*stats)))\n",
    "    feature_len = len(trans)\n",
    "    assert feature_len % 3 == 0\n",
    "\n",
    "    ret = {}\n",
    "    for i in range(feature_len // 3):\n",
    "        label = (\"mean\" if i < feature_len // 3 else\n",
    "                 \"median\" if i < 2 * feature_len // 3 else \"std\")\n",
    "        ret[f\"latent_embedding_{label}_{i%3}\"] = trans[i]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2f1dd1-1ff2-474c-af82-e2db43206684",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_embedding_statistics = get_latent_embedding_statistics(analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de27fc-f6e1-4a4b-95f1-60e541a0fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syllable_frequencies(analyses: analyses_t):\n",
    "    stats_df = analyses[\"stats_df\"]\n",
    "    \n",
    "    freq_wide = stats_df.pivot(index=\"name\", columns=\"syllable\", values=\"frequency\").fillna(0)\n",
    "    freq_array = freq_wide.to_numpy()\n",
    "    return {f\"syllable_frequency_{i}\": list(freq_array[:, i]) for i in range(freq_array.shape[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b36f65-d022-4712-b6c3-d53b18da34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_frequencies = get_syllable_frequencies(analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ae292-b56d-4751-81e0-d84e42669cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_mats(analyses: analyses_t, *, min_frequency: float=0.005, normalize=\"bigram\", enable_visualization=False):\n",
    "    project_dir, model_name = _read_project_info(\"project_dir\", \"model_name\")\n",
    "\n",
    "    trans_mats, usages, groups, syll_include = kpms.generate_transition_matrices(\n",
    "        project_dir, model_name, normalize=normalize, min_frequency=min_frequency\n",
    "    )\n",
    "\n",
    "    if enable_visualization:\n",
    "        kpms.visualize_transition_bigram(\n",
    "            project_dir,\n",
    "            model_name,\n",
    "            groups,\n",
    "            trans_mats,\n",
    "            syll_include,\n",
    "            normalize=normalize,\n",
    "            show_syllable_names=False,\n",
    "            save_dir=FIGURE_DIR\n",
    "        )\n",
    "\n",
    "    trans_mats = np.stack(trans_mats)\n",
    "    n = len(trans_mats[0])\n",
    "    return {f\"transition_mat_{i}_{j}\": list(trans_mats[:, i, j]) for i in range(n) for j in range(n)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf49bc9a-64b5-43f8-875a-8e014d20bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "transition_mats = get_transition_mats(analyses, normalize=\"row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15045178-b1c2-492b-8fe6-b70d6236474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syllable_shannon_entropy(analyses: analyses_t):\n",
    "    stats_df = analyses[\"stats_df\"]\n",
    "    \n",
    "    freq_wide = stats_df.pivot(index=\"name\", columns=\"syllable\", values=\"frequency\").fillna(0)\n",
    "    freq_array = freq_wide.to_numpy()\n",
    "    return {f\"syllable_shannon_entropy\": [entropy(freq_array[i, :]) for i in tqdm(range(len(freq_array)), desc=\"computing get_syllable_shannon_entropy\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce8b6f-8156-4f7c-9ab7-8738872670ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_shannon_entropy = get_syllable_shannon_entropy(analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a140fb-9b01-469f-9e98-b7f80c0dc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_distinct_syllables(analyses: analyses_t, *, ths: Sequence[float]):\n",
    "    results = analyses[\"results\"]\n",
    "    n = len(results)\n",
    "    freqs = [np.bincount(info[\"syllable\"]) / len(info[\"syllable\"]) for name, info in results.items()]\n",
    "    return {\n",
    "        f\"num_distinct_syllables_th_{th}\": [int((freqs[i] > th).sum()) for i in range(n)]\n",
    "        for th in ths\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd07dc8-5e83-449f-a353-0ecc30d140fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distinct_syllables = get_num_distinct_syllables(analyses, ths=[0.005, 0.02, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80730c54-7978-443a-8982-e68e2a607996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def merge_features(analyses: analyses_t, features: Sequence[Dict[str, Sequence[Any]]]):\n",
    "    merged_features = reduce(operator.or_, [{\"name\": list(analyses[\"results\"].keys())}] + features, {})\n",
    "    return pd.DataFrame(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e17e2b-ca80-442c-a6d4-a73283036661",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = merge_features(analyses, [syllable_lz_output, latent_embedding_statistics, syllable_frequencies, transition_mats, syllable_shannon_entropy, num_distinct_syllables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f98866-1cb3-45f3-b5b0-3300e714d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bef5a-6f0c-4e1a-9295-b5b41434b36a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
